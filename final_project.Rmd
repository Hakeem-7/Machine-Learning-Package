---
title: "Final Project, Group 5, STAT 6210"
author: "Akeem Ajede, Cary Burdick, Kaelyn Fogelman, Maria Tereza Bethonico Terra"
date: "12/04/2020"
output: html_document
---
Repository: [Final_Project_Group_5](https://github.com/AU-R-Programming/Final_Project_Group_5)
\
\
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Packages
<div class="alert alert-warning">
  <strong>This will be used to install any packages needed for code. Currently, the only package needed is for accessing a sample dataset. To remove all dependencies on outside packages, we may want to create our own dataset.
</div>
```{r trueinstall, message=FALSE, warning=FALSE}

# Installing any necessary packages
if (!require("gamair")) {
    install.packages("gamair")
    library(ggplot2)
}

```



## Linear Regression

```{r linear_regression, error=TRUE}

# Example dataset from textbook, but we can change this
data(hubble)

my_lm = function(response, covariates, alpha=0.05, method="asymptotic") {
  
  # Putting the data in a matrix format
  response <- as.matrix(response)
  covariates <- as.matrix(covariates)
  
  # Check to see if they are of the same row length
  if(nrow(response) != nrow(covariates)) 
    stop('The number of rows of the response and predictor variables must be equal.')
  
  # Check to see if alpha is between 0 and 1
  if(alpha >= 1 | alpha <= 0) 
    stop('True value of alpha must lie between 0 and 1')
  
  # Produce a warning if alpha is greater than 0.1 (i.e is lower than 90% confidence interval)
  if(alpha > 0.1) 
    warning('Alpha is typically between 0.01 and 0.1. Consider using a different alpha value')
  
  # Check to see if appropriate method has been listed
  if(method != "asymptotic" & method != "a" & method != "bootstrap" & method != "b")
    stop('Unrecognized confidence interval method. Try "asymptotic" or "bootstrap".')

  # Define parameters
  int <- rep(1, length(response))
  covariates <- as.matrix(cbind(int, covariates))
  n <- length(response)
  p <- dim(covariates)[2] # Column of the parameters/predictors
  df <- n - p # degree of freedom
  dfm <- p - 1
  dfe <- n - p
  j <- matrix(1, nrow=n, ncol=n)
  one <- rep(1, n)

  
  # Calculate statistics
  beta.hat <- solve(t(covariates)%*%covariates)%*%t(covariates)%*%response
  resid <- response - covariates%*%as.matrix(beta.hat) 
  sigma2.hat <- (1/df)*t(resid)%*%resid
  var.beta <- t(sigma2.hat%*%diag(solve(t(covariates)%*%covariates)))
  y.hat <- covariates%*%beta.hat
  mspe <- (sum((response - y.hat)^2))/n
  y.avg <- (t(response)%*%one)/n
  ssm <- t(y.hat-y.avg[1])%*%(y.hat-y.avg[1])
  sse <- t(response-y.hat)%*%(response-y.hat)
  msm <- ssm/dfm
  mse <- sse/dfe
  f.stat <- msm/mse
  p.value <- pf(f.stat, dfm, dfe, lower.tail=FALSE)
  
  # Defining parameter for confidence interval based on specified alpha
  quant <- 1 - alpha/2
  
  # Change CI calculation based on specified method
  if(tolower(method) == "asymptotic" | tolower(method) == "a"){
    iter = length(beta.hat)
    ci.beta <- NULL
    for(i in 1:length(beta.hat)){
    ci.list <- c(beta.hat[i] - qnorm(p = quant)*sqrt(var.beta[i]), beta.hat[i] + 
                   qnorm(p = quant)*sqrt(var.beta[i]))
    ci.beta <- rbind(ci.beta, ci.list)
    }
  } else{
    data <- cbind(response, covariates)
    i = 1
    beta.hats <- NULL
    while(i<=1000){
      boot.data <- data[sample(nrow(data),size=n,replace=TRUE),]
      beta.hat.boot <- solve(t(boot.data[,2])%*%boot.data[,2])%*%t(boot.data[,2])%*%boot.data[,1]
      beta.hats <- append(beta.hats, beta.hat.boot)
      i <- i+1
    }
    ci.beta <- quantile(beta.hats, c(alpha/2, 1-(alpha/2)))
  }
  return(list(beta = beta.hat, sigma2 = sigma2.hat, 
              variance_beta = var.beta, ci = ci.beta, mspe = mspe,
              ssm = ssm, sse = sse, f.stat = f.stat, p.value = p.value,
              residuals = resid, y.hat = y.hat))
}



# Bootstrap CI method
fit_my_lm = my_lm(hubble$y, hubble$x, 0.05, "bootstrap")
fit_my_lm

# Asymptotic CI method
fit_my_lm2 = my_lm(hubble$y, hubble$x, 0.05, "asymptotic")
fit_my_lm2

# Showing off an error message
fit_my_lm3 = my_lm(hubble$y, hubble$x, 02, "asymptotic")
fit_my_lm3

# Using standard lm package
fit_lm <- lm(hubble$y ~ hubble$x - 1) # -1 eliminates the intercept


```





```{r Performance Comparison}

# Comparing the output of our lm function with the base package

base_result = c(fit_lm$coefficients, 
                 (1/fit_lm$df.residual)*t(fit_lm$residuals)%*%fit_lm$residuals)

manual_result_bootstrap = c(fit_my_lm$beta, fit_my_lm$sigma2)

manual_result_asymptotic = c(fit_my_lm2$beta, fit_my_lm2$sigma2)

result = cbind(base_result, manual_result_asymptotic, manual_result_bootstrap)
row.names(result) = c("Beta", "Sigma")
result

```





```{r Plots}

plot_func <- function(lm){
  plot(lm$y.hat, lm$residual)

  qqnorm(lm$residual)
  qqline(lm$residual, col = "red", lwd = 2)

  hist(lm$residual)

}

plot_func(fit_my_lm)

```

